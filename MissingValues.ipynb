{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MissingValues.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMZSYPvObmXr38ODQMPZowL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehrdadkazemi254/MachineLearning/blob/main/MissingValues.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WU0Q1HzNtSdu"
      },
      "source": [
        "**Three ways to deal with missing values:**\n",
        "\n",
        "\n",
        "1.   Delete the entire column with a missing value\n",
        "2.   Imputation\n",
        "3.   Imputation + Adding a new column indicating the location of imputed values\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hJG2irXuWdH"
      },
      "source": [
        "We first import the data which could be downloaded from here:\n",
        "https://www.kaggle.com/dansbecker/melbourne-housing-snapshot/home\n",
        "\n",
        "Then, we define a function to measure the performance ( in this case accuracy ) of each method and use it compare them.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ojlpw0MvBRa"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = pd.read_csv('melb_data.csv')\n",
        "\n",
        "#select the target variable\n",
        "y = data['Price']\n",
        "predictors = data.drop(['Price'], axis=1)\n",
        "\n",
        "#select the predictors\n",
        "X = predictors.select_dtypes(exclude=['object'])\n",
        "\n",
        "#divide data into training and validation\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X,y, train_size= 0.8, test_size= 0.2, random_state= 0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgu3ercBs1Dq"
      },
      "source": [
        "#define a function to measure mean absolute error(MAE)\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "def get_mae(X_train,X_valid,y_train,y_valid):\n",
        "  model = RandomForestRegressor(n_estimators= 10, random_state= 0)\n",
        "  model.fit(X_train,y_train)\n",
        "  predicts = model.predict(X_valid)\n",
        "  return mean_absolute_error(y_valid,predicts)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLatFh_iyH9N"
      },
      "source": [
        "**Approach 1:**\n",
        "Drop columns with missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE7qSJnkySXU",
        "outputId": "86520777-a9d8-472f-8de5-40c58c6b2a5f"
      },
      "source": [
        "#we first need to identify columns with missing values\n",
        "\n",
        "missing_values_cols = [col for col in X.columns if X[col].isnull().any()]\n",
        "print(f\"Columns with missing values are: {missing_values_cols}\") \n",
        "\n",
        "\n",
        "shrunk_X_train = X_train.drop(missing_values_cols, axis=1)\n",
        "shrunk_X_valid = X_valid.drop(missing_values_cols, axis=1)\n",
        "\n",
        "print(\"MAE from Approach 1 (Drop columns with missing values):\")\n",
        "print(get_mae(shrunk_X_train,shrunk_X_valid,y_train,y_valid))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns with missing values are: ['Car', 'BuildingArea', 'YearBuilt']\n",
            "MAE from Approach 1 (Drop columns with missing values):\n",
            "183550.22137772635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIffC2Dgzv5l"
      },
      "source": [
        "**Approach 2:**\n",
        "imputation--> we can use different techniques to impute missing values. here, we will use the average value of that column for imputation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHmny6qV0Pj_",
        "outputId": "77afd891-bf46-48cd-befb-66ef9af2ba91"
      },
      "source": [
        "#choose imputer\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "my_imputer = SimpleImputer()\n",
        "\n",
        "#imputation for X_train and X_valid\n",
        "\n",
        "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
        "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
        "\n",
        "#notice that we used .fit_transform for X_train to train the model but when it comes to the validation data we only use .transform since we\n",
        "#do not want the model to have the advantage of using the validation dataset to make better predictions.\n",
        "\n",
        "#imputation removes the columns' names; hence, we need to rename them again\n",
        "\n",
        "imputed_X_train.columns = X_train.columns\n",
        "imputed_X_valid.columns = X_valid.columns\n",
        "\n",
        "print(\"MAE from Approach 2 (Imputation using the mean value):\")\n",
        "print(get_mae(imputed_X_train,imputed_X_valid,y_train,y_valid))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE from Approach 2 (Imputation using the mean value):\n",
            "178166.46269899711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9TVTQVg2Xqq"
      },
      "source": [
        "**Approach 3:**\n",
        "An extension to imputation: we'll add another column to represent the locaion of the imputed values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_QKaBlh2vLe",
        "outputId": "5840e80e-84c2-4b81-ca6e-5659f82e39ef"
      },
      "source": [
        "#we get a copy of the data first, so that we can build our modified dataset for this approach\n",
        "\n",
        "X_train_plus = X_train.copy()\n",
        "X_valid_plus = X_valid.copy()\n",
        "\n",
        "#making a new column that shows the location of imputed values\n",
        "\n",
        "for col in missing_values_cols:\n",
        "  X_train_plus[col + 'was_missing?'] = X_train_plus[col].isnull()\n",
        "  X_valid_plus[col + 'was_missing?'] = X_valid_plus[col].isnull()\n",
        "#ignore the resulted error for now\n",
        "\n",
        "#Imputation\n",
        "imputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\n",
        "imputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))\n",
        "\n",
        "#Imputation removes colums, so we need to rename the columns\n",
        "imputed_X_train_plus.columns = X_train_plus.columns\n",
        "imputed_X_valid_plus.columsn = X_valid_plus.columns\n",
        "\n",
        "print(\"MAE from Approach 3 (An Extension to Imputation):\")\n",
        "print(get_mae(imputed_X_train_plus, imputed_X_valid_plus, y_train, y_valid))\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE from Approach 3 (An Extension to Imputation):\n",
            "178927.503183954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFTUGC1z7fc3"
      },
      "source": [
        "### As you can see, Imputation outperforms dropping the entire column\n",
        "---\n"
      ]
    }
  ]
}